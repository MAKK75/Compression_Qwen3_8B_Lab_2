
# Lab 2: LLM Compression (Stage 1) - Qwen3-8B AWQ

В данном репозитории представлено решение **Этапа 1** лабораторной работы по компрессии LLM.
Цель: Сжать модель **Qwen3-8B** с минимальной потерей качества на бенчмарке **MMLU**.

Метод сжатия: **AWQ (Activation-aware Weight Quantization)** 4-bit.

## Результаты

| Метрика | Значение | Комментарий |
| :--- | :--- | :--- |
| **Original Size** | 15.26 GB | FP16 |
| **Compressed Size** | 5.68 GB | INT4 (AWQ) |
| **Compression Ratio** | **2.69x** | |
| **Baseline Accuracy (MMLU)** | 0.7292 (72.92%) | |
| **Compressed Accuracy (MMLU)** | 0.7167 (71.67%) | |
| **Performance Drop** | 1.72% | |
| **Final Score** | **2.64** | `Ratio / (1 + Drop)` |

Детальное сравнение по каждой теме бенчмарка доступно в файле: [mmlu_comparison_detailed.csv](./mmlu_comparison_detailed.csv)

## Ссылки на модели

1.  **Исходная модель:** [Qwen/Qwen3-8B](https://huggingface.co/Qwen/Qwen3-8B)
2.  **Сжатая модель (моя):** [NOVORDSEC/qwen3-8b-awq-int4](https://huggingface.co/NOVORDSEC/qwen3-8b-awq-int4)

---

## Установка и Запуск

Проект можно запустить двумя способами: через готовые Python-скрипты или через Jupyter Notebook.

### Предварительные требования
*   **GPU:** Требуется видеокарта NVIDIA (код тестировался на T4 16GB).
*   **Python:** 3.12

### Установка зависимостей

```bash
pip install -r requirements.txt
```

---

### Способ 1: Python скрипты

Этот способ воспроизводит логику шаг за шагом.

#### Шаг 1. Сжатие модели
Скрипт скачивает оригинальную модель, калибрует квантование и сохраняет сжатую версию в папку `./qwen3-8b-awq`.

```bash
python compress.py
```
*Примечание: Если вы хотите использовать уже загруженные веса с HuggingFace, этот шаг можно пропустить.*

#### Шаг 2. Замер метрик и параметров
Скрипт скачивает (или берет локально) сжатую модель, запускает MMLU бенчмарк (20% выборки для ускорения, как в условии) и считает Score.

```bash
python benchmark.py
```
*По умолчанию `benchmark.py` настроен на загрузку готовых весов из `NOVORDSEC/qwen3-8b-awq-int4`. Чтобы проверить локальную папку, отредактируйте переменную `COMP_MODEL_ID` в скрипте.*

---

### Способ 2: Jupyter Notebook

Весь пайплайн (установка библиотек, сжатие, выгрузка, тесты) собран в одном ноутбуке. Это тот же код, который запускался на Kaggle.

1. Откройте файл `Stage1_Compression_And_Benchmark.ipynb`.
2. Запустите ячейки последовательно.

---

## Дополнительная информация

*   **Оборудование:** Код запускался на Kaggle (2x Tesla T4).
*   **Методология:** Использовался `AutoAWQ` с настройками GEMM, w_bit=4, group_size=128.
*   **Бенчмарк:** MMLU (Massive Multitask Language Understanding) через библиотеку `datasets`. Использовалась выборка `fraction=0.2` для оптимизации времени выполнения.

